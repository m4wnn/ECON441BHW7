{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e73abd3f",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "<div style=\"text-align: left;\">\n",
    "    <h1>Week 7 - Laboratory</h1>\n",
    "    <h4>ECON441B</h3>\n",
    "    <div style=\"padding: 20px 0;\">\n",
    "        <hr style=\"border: 0; height: 1px; background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));\">\n",
    "        <p><em>Mauricio Vargas-Estrada</em><br>\n",
    "        Master in Quantitative Economics<br>\n",
    "        University of California - Los Angeles</p>\n",
    "        <hr style=\"border: 0; height: 1px; background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8bacc0bb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import wikipedia\n",
    "\n",
    "from tmp import api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dccde62",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "1. Set up OpenAI and the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09ced8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.Client(\n",
    "    api_key=api_key()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3fcef5",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "2. Use the `wikipedia` API to get a function that pulls in the text of a `wikipedia` page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d241e671",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# get_wiki = lambda page: wikipedia.page(page).content\n",
    "get_wiki = lambda term: wikipedia.summary(term, sentences=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193bb241",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "3. Build a `chatgpt` bot that will analyze the text given and try to locate any false info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ddb68bc2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def check_info_wikipedia(text, role):\n",
    "    tmp = client.chat.completions.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': role\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': text\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return tmp.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9376f514",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "4. Make a for loop and check a few wikipedia pages and return a report of any potentially false info via wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "febcbc1d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "terms = [\n",
    "    'Bootstrap',\n",
    "    'Statistics',\n",
    "    'Stationarity',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "291745be",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "temp_role_definition = f\"\"\"\n",
    "- You have to locate FALSE information from a a serie of sentences. \n",
    "- If a sentence seems TRUE, return 1, otherwise return 0.\n",
    "- If you are not sure, return a value between 0 and 1 that represents your confidence level.\n",
    "- Return the sequence of values like a python list.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b87734f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking veracity for: Bootstrap ...\n",
      "[1, 1, 0]\n",
      "Checking veracity for: Statistics ...\n",
      "[\n",
      "1,\n",
      "1,\n",
      "1,\n",
      "1,\n",
      "0,\n",
      "1,\n",
      "1,\n",
      "0,\n",
      "1,\n",
      "1,\n",
      "1,\n",
      "1,\n",
      "1,\n",
      "1,\n",
      "1,\n",
      "1,\n",
      "1\n",
      "]\n",
      "Checking veracity for: Stationarity ...\n",
      "[1, 1, 1, 0, 1, 0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "\n",
    "for t in terms:\n",
    "    print(f'Checking veracity for: {t} ...')\n",
    "    responses.append(\n",
    "        check_info_wikipedia(\n",
    "            get_wiki(t),\n",
    "            temp_role_definition\n",
    "        )\n",
    "    )\n",
    "    print(responses[-1])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:percent,ipynb",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "chatgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
